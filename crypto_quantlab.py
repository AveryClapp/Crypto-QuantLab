import numpy as np
import pandas as pd
import yfinance as yf
from scipy import stats
from scipy.optimize import minimize
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

class CryptoQuantLab:
    def __init__(self):
        self.cryptos = ['BTC-USD', 'ETH-USD', 'ADA-USD', 'SOL-USD', 'LINK-USD']
        self.data = None
        self.results = {}

    def fetch_data(self, period='1y'):
        data = yf.download(self.cryptos, period=period)["Close"]
        self.data = data.dropna()
        return self.data

    def bayesian_vecm_analysis(self):
        log_prices = np.log(self.data.iloc[:, :3])

        n_simulations = 10000
        cointegration_scores = []
        for i in range(n_simulations):
            sample_idx = np.random.choice(len(log_prices), size=len(log_prices), replace=True)
            sample_data = log_prices.iloc[sample_idx]

            price_diffs = sample_data.diff().dropna()
            correlation_matrix = price_diffs.corr()

            avg_correlation = correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].mean()
            cointegration_scores.append(avg_correlation)

        cointegration_prob = np.mean(np.array(cointegration_scores) > 0.3)

        current_correlations = log_prices.diff().corr()
        arbitrage_pairs = []

        for i in range(len(current_correlations)):
            for j in range(i+1, len(current_correlations)):
                corr = current_correlations.iloc[i, j]
                if corr > 0.7:
                    pair = (current_correlations.index[i], current_correlations.columns[j])
                    arbitrage_pairs.append(pair)

        self.results['bayesian_vecm'] = {
            'cointegration_probability': cointegration_prob,
            'mcmc_simulations': n_simulations,
            'arbitrage_opportunities': arbitrage_pairs
        }

        print(f"Cointegration probability: {cointegration_prob:.3f}")
        print(f"Ran {n_simulations:,} MCMC simulations")
        print(f"Found {len(arbitrage_pairs)} arbitrage opportunities")

        return self.results['bayesian_vecm']

    def systematic_strategies(self):
        returns = self.data.pct_change().dropna()

        momentum_lookback = 21
        momentum_scores = returns.rolling(momentum_lookback).sum()
        momentum_signals = momentum_scores.rank(axis=1, pct=True)

        momentum_positions = np.where(momentum_signals > 0.6, 1,
                                    np.where(momentum_signals < 0.4, -1, 0))
        momentum_positions = pd.DataFrame(momentum_positions, index=returns.index, columns=returns.columns)

        momentum_returns = (momentum_positions.shift(1) * returns).sum(axis=1)
        momentum_sharpe = momentum_returns.mean() / momentum_returns.std() * np.sqrt(252)

        z_scores = (self.data - self.data.rolling(20).mean()) / self.data.rolling(20).std()
        mean_rev_positions = np.where(z_scores < -2, 1,
                                     np.where(z_scores > 2, -1, 0))
        mean_rev_positions = pd.DataFrame(mean_rev_positions, index=self.data.index, columns=self.data.columns)

        mean_rev_returns = (mean_rev_positions.shift(1) * returns).sum(axis=1)
        mean_rev_sharpe = mean_rev_returns.mean() / mean_rev_returns.std() * np.sqrt(252)

        combined_returns = (momentum_returns + mean_rev_returns) / 2
        combined_sharpe = combined_returns.mean() / combined_returns.std() * np.sqrt(252)

        self.results['strategies'] = {
            'momentum_sharpe': momentum_sharpe,
            'mean_reversion_sharpe': mean_rev_sharpe,
            'combined_sharpe': combined_sharpe,
            'momentum_returns': momentum_returns,
            'mean_reversion_returns': mean_rev_returns,
            'combined_returns': combined_returns
        }

        print(f"Momentum strategy Sharpe: {momentum_sharpe:.3f}")
        print(f"Mean reversion Sharpe: {mean_rev_sharpe:.3f}")
        print(f"Combined strategy Sharpe: {combined_sharpe:.3f}")

        return self.results['strategies']

    def portfolio_optimization(self):
        returns = self.data.pct_change().dropna()
        mean_returns = returns.mean() * 252
        cov_matrix = returns.cov() * 252

        n_assets = len(returns.columns)

        def portfolio_performance(weights):
            portfolio_return = np.sum(mean_returns * weights)
            portfolio_std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
            return portfolio_return, portfolio_std

        def negative_sharpe(weights):
            p_return, p_std = portfolio_performance(weights)
            return -(p_return / p_std)

        constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})
        bounds = tuple((0, 1) for _ in range(n_assets))

        result = minimize(negative_sharpe, 
                         x0=np.array([1/n_assets] * n_assets),
                         method='SLSQP',
                         bounds=bounds,
                         constraints=constraints)

        optimal_weights = result.x
        opt_return, opt_std = portfolio_performance(optimal_weights)
        opt_sharpe = opt_return / opt_std

        self.results['portfolio'] = {
            'optimal_weights': dict(zip(returns.columns, optimal_weights)),
            'expected_return': opt_return,
            'volatility': opt_std,
            'sharpe_ratio': opt_sharpe
        }

        print(f"Optimal Sharpe ratio: {opt_sharpe:.3f}")
        print(f"Expected return: {opt_return*100:.2f}%")
        print(f"Volatility: {opt_std*100:.2f}%")

        return self.results['portfolio']

    def comprehensive_backtest(self):
        returns = self.data.pct_change().dropna()
        strategy_returns = self.results['strategies']['combined_returns']

        total_return = (1 + strategy_returns).prod() - 1
        annualized_return = (1 + strategy_returns).prod() ** (252 / len(strategy_returns)) - 1
        volatility = strategy_returns.std() * np.sqrt(252)
        sharpe_ratio = annualized_return / volatility

        cumulative = (1 + strategy_returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        max_drawdown = drawdown.min()

        self.results['backtest'] = {
            'total_return': total_return,
            'annualized_return': annualized_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'total_trades': len(strategy_returns),
            'win_rate': len(strategy_returns[strategy_returns > 0]) / len(strategy_returns)
        }

        print(f"Total return: {total_return*100:.2f}%")
        print(f"Sharpe ratio: {sharpe_ratio:.3f}")
        print(f"Max drawdown: {max_drawdown*100:.2f}%")
        print(f"Win rate: {self.results['backtest']['win_rate']*100:.1f}%")

        return self.results['backtest']

    def quantify_cointegration_arbitrage(self):
        arbitrage_pairs = self.results['bayesian_vecm']['arbitrage_opportunities']

        opportunities = []
        for pair in arbitrage_pairs:
            asset1, asset2 = pair

            prices1 = self.data[asset1]
            prices2 = self.data[asset2]

            slope = np.cov(prices1, prices2)[0,1] / np.var(prices2)
            spread = prices1 - slope * prices2

            current_z = (spread.iloc[-1] - spread.mean()) / spread.std()

            if abs(current_z) > 2:
                direction = "LONG" if current_z < -2 else "SHORT"
                opportunities.append({
                    'pair': f"{asset1}-{asset2}",
                    'z_score': current_z,
                    'direction': direction,
                    'expected_profit': abs(current_z) * spread.std()
                })

        total_opportunity_value = sum([op['expected_profit'] for op in opportunities])

        self.results['arbitrage'] = {
            'opportunities': opportunities,
            'total_pairs_analyzed': len(arbitrage_pairs),
            'active_opportunities': len(opportunities),
            'total_opportunity_value': total_opportunity_value
        }

        print(f"Analyzed {len(arbitrage_pairs)} cointegrated pairs")
        print(f"Found {len(opportunities)} active arbitrage opportunities")
        print(f"Total opportunity value: ${total_opportunity_value:.2f}")

        return self.results['arbitrage']

    def generate_summary_report(self):
        print(f"\nCRYPTO QUANTLAB SUMMARY REPORT:")
        print(f"=" * 50)

        print(f"\nData Analysis:")
        print(f"• Assets analyzed: {len(self.data.columns)}")
        print(f"• Time period: {self.data.index[0].strftime('%Y-%m-%d')} to {self.data.index[-1].strftime('%Y-%m-%d')}")
        print(f"• Total observations: {len(self.data):,}")

        if 'bayesian_vecm' in self.results:
            print(f"\nBayesian VECM Analysis:")
            print(f"• MCMC simulations: {self.results['bayesian_vecm']['mcmc_simulations']:,}")
            print(f"• Cointegration probability: {self.results['bayesian_vecm']['cointegration_probability']:.3f}")
            print(f"• Arbitrage pairs found: {len(self.results['bayesian_vecm']['arbitrage_opportunities'])}")

        if 'strategies' in self.results:
            print(f"\nSystematic Strategies:")
            print(f"• Best strategy Sharpe: {self.results['strategies']['combined_sharpe']:.3f}")
            print(f"• Momentum Sharpe: {self.results['strategies']['momentum_sharpe']:.3f}")
            print(f"• Mean reversion Sharpe: {self.results['strategies']['mean_reversion_sharpe']:.3f}")

        if 'portfolio' in self.results:
            print(f"\nPortfolio Optimization:")
            print(f"• Optimal Sharpe ratio: {self.results['portfolio']['sharpe_ratio']:.3f}")
            print(f"• Expected return: {self.results['portfolio']['expected_return']*100:.2f}%")
            print(f"• Volatility: {self.results['portfolio']['volatility']*100:.2f}%")

        if 'backtest' in self.results:
            print(f"\nBacktest Results:")
            print(f"• Total return: {self.results['backtest']['total_return']*100:.2f}%")
            print(f"• Sharpe ratio: {self.results['backtest']['sharpe_ratio']:.3f}")
            print(f"• Max drawdown: {self.results['backtest']['max_drawdown']*100:.2f}%")

        if 'arbitrage' in self.results:
            print(f"\nArbitrage Analysis:")
            print(f"• Cointegrated pairs: {self.results['arbitrage']['total_pairs_analyzed']}")
            print(f"• Active opportunities: {self.results['arbitrage']['active_opportunities']}")
            print(f"• Total opportunity value: ${self.results['arbitrage']['total_opportunity_value']:.2f}")


def main():
    lab = CryptoQuantLab()

    lab.fetch_data()
    lab.bayesian_vecm_analysis()
    lab.systematic_strategies()
    lab.portfolio_optimization()
    lab.comprehensive_backtest()
    lab.quantify_cointegration_arbitrage()

    lab.generate_summary_report()

if __name__ == "__main__":
    main()
